from vector_store import VectorStore
from functions import get_rag_response
import streamlit as st
import requests

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã¨èª­ã¿è¾¼ã¿
vector_store_instance = VectorStore()
vector_store = vector_store_instance.read()

# API Keyã®å–å¾—
openai_api_key = st.secret["OPENAI_API_KEY"]




# ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
st.title("ğŸ¤– RAGã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

# 1. åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# 2. å±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 3. å…¥åŠ›ã¨å±¥æ­´è¿½åŠ 
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ä¿å­˜ï¼†è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # RAGã‚’ä½¿ã£ãŸå¿œç­”ã®ç”Ÿæˆ
    ai_message = get_rag_response(prompt, vector_store, openai_api_key)

    # AIã®è¿”ç­”ã‚’ä¿å­˜ï¼†è¡¨ç¤ºï¼ˆã‚ªã‚¦ãƒ è¿”ã—â†’RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«å¤‰æ›´ï¼‰
    st.session_state.messages.append({"role": "assistant", "content": ai_message})
    with st.chat_message("assistant"):
        st.markdown(ai_message)